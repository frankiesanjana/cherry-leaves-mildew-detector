{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Notebook 01 - Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and save as raw data in organised folders\n",
        "* Inspect the data and check for non-image files\n",
        "* Split the data into Train, Test and Validation sets\n",
        "* Save the split data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file - authentication token\n",
        "* Kaggle dataset\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Image files saved in separate folders for healthy leaves and those with powdery mildew, within each of train, test and validation sets\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* By the end of this workbook, the dataset has no non-image files, and the files are now split in the desired ratio between test, train and validation sets.\n",
        "* Next, we will proceed to data visualisation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import stat\n",
        "import shutil\n",
        "import random\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\franc\\\\cherry-leaves-mildew-detector\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\franc\\\\cherry-leaves-mildew-detector'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Fetch data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset can now be fetched from Kaggle, where it is stored.\n",
        "\n",
        "Firstly, the Kaggle package is installed to allow fetching of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle==1.5.12 in c:\\users\\franc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\franc\\appdata\\roaming\\python\\python38\\site-packages (from kaggle==1.5.12) (1.16.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\franc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from kaggle==1.5.12) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\franc\\appdata\\roaming\\python\\python38\\site-packages (from kaggle==1.5.12) (2.8.2)\n",
            "Requirement already satisfied: requests in c:\\users\\franc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from kaggle==1.5.12) (2.29.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\franc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from kaggle==1.5.12) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\franc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from kaggle==1.5.12) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in c:\\users\\franc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from kaggle==1.5.12) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\franc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-slugify->kaggle==1.5.12) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\franc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->kaggle==1.5.12) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\franc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->kaggle==1.5.12) (3.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\franc\\appdata\\roaming\\python\\python38\\site-packages (from tqdm->kaggle==1.5.12) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# install kaggle package\n",
        "%pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `kaggle.json` file is then imported to the workspace to authenticate the request to access the data from Kaggle\n",
        "\n",
        "This file will not be seen in the public repository since it is linked to my personal Kaggle account and as such is listed in the `.gitignore` file\n",
        "The following cell sets the Kaggle API config directory, gets the path to the `kaggle.json` file and then sets the file permissions for the `kaggle.json` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "kaggle_json_path = os.path.join(os.getcwd(), 'kaggle.json')\n",
        "os.chmod(kaggle_json_path, stat.S_IREAD | stat.S_IWRITE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset can now be imported:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading cherry-leaves.zip to inputs/cherry_leaves_dataset\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0.00/55.0M [00:00<?, ?B/s]\n",
            "  2%|▏         | 1.00M/55.0M [00:00<00:52, 1.07MB/s]\n",
            "  4%|▎         | 2.00M/55.0M [00:01<00:27, 2.06MB/s]\n",
            "  7%|▋         | 4.00M/55.0M [00:01<00:12, 4.40MB/s]\n",
            " 11%|█         | 6.00M/55.0M [00:01<00:07, 6.91MB/s]\n",
            " 16%|█▋        | 9.00M/55.0M [00:01<00:04, 10.5MB/s]\n",
            " 20%|█▉        | 11.0M/55.0M [00:01<00:04, 10.8MB/s]\n",
            " 25%|██▌       | 14.0M/55.0M [00:01<00:02, 14.5MB/s]\n",
            " 31%|███       | 17.0M/55.0M [00:02<00:02, 15.7MB/s]\n",
            " 38%|███▊      | 21.0M/55.0M [00:02<00:01, 18.3MB/s]\n",
            " 44%|████▎     | 24.0M/55.0M [00:02<00:01, 20.4MB/s]\n",
            " 49%|████▉     | 27.0M/55.0M [00:02<00:01, 19.9MB/s]\n",
            " 55%|█████▍    | 30.0M/55.0M [00:02<00:01, 21.0MB/s]\n",
            " 60%|█████▉    | 33.0M/55.0M [00:02<00:01, 20.9MB/s]\n",
            " 65%|██████▌   | 36.0M/55.0M [00:02<00:00, 21.0MB/s]\n",
            " 71%|███████   | 39.0M/55.0M [00:03<00:00, 21.2MB/s]\n",
            " 78%|███████▊  | 43.0M/55.0M [00:03<00:00, 22.2MB/s]\n",
            " 84%|████████▎ | 46.0M/55.0M [00:03<00:00, 20.9MB/s]\n",
            " 89%|████████▉ | 49.0M/55.0M [00:03<00:00, 20.5MB/s]\n",
            " 95%|█████████▍| 52.0M/55.0M [00:04<00:00, 13.2MB/s]\n",
            "100%|██████████| 55.0M/55.0M [00:04<00:00, 14.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "DestinationFolder = \"inputs/cherry_leaves_dataset\"\n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, the files are unzipped and the kaggle.json file is removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "for file in os.listdir(DestinationFolder):\n",
        "    if file.endswith(\".zip\"):\n",
        "        file_path = os.path.join(DestinationFolder, file)\n",
        "        shutil.unpack_archive(file_path, DestinationFolder)\n",
        "        os.remove(file_path)\n",
        "\n",
        "os.remove(\"kaggle.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for and remove any non-image files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_non_image_file(my_data_dir):\n",
        "    image_extension = ('.png', '.jpg', '.jpeg')\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files = os.listdir(my_data_dir + '/' + folder)\n",
        "        # print(files)\n",
        "        i = []\n",
        "        j = []\n",
        "        for given_file in files:\n",
        "            if not given_file.lower().endswith(image_extension):\n",
        "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
        "                os.remove(file_location)  # remove non image file\n",
        "                i.append(1)\n",
        "            else:\n",
        "                j.append(1)\n",
        "                pass\n",
        "        print(f\"Folder: {folder} - has image file\", len(j))\n",
        "        print(f\"Folder: {folder} - has non-image file\", len(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder: healthy - has image file 2104\n",
            "Folder: healthy - has non-image file 0\n",
            "Folder: powdery_mildew - has image file 2104\n",
            "Folder: powdery_mildew - has non-image file 0\n"
          ]
        }
      ],
      "source": [
        "remove_non_image_file(my_data_dir='inputs/cherry_leaves_dataset/cherry-leaves')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After this step, the dataset should not contain any images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split Train, Test and Validation sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The images are now split into train, test and validation sets and divided into respective folders, with separate folders within each of these for images of healthy leaves and images of leaves infected with powdery mildew."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "  \n",
        "  if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "    print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "    return\n",
        "\n",
        "  # gets classes' labels\n",
        "  labels = os.listdir(my_data_dir) # gets the folder names\n",
        "  if 'test' in labels:\n",
        "    pass\n",
        "  else: \n",
        "    # create train, test folders with classes labels sub-folder\n",
        "    for folder in ['train','validation','test']:\n",
        "      for label in labels:\n",
        "        os.makedirs(name=my_data_dir+ '/' + folder + '/' + label)\n",
        "\n",
        "    for label in labels:\n",
        "\n",
        "      files = os.listdir(my_data_dir + '/' + label)\n",
        "      random.shuffle(files)\n",
        "\n",
        "      train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "      validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "      count = 1\n",
        "      for file_name in files:\n",
        "        if count <= train_set_files_qty:\n",
        "          # move given file to train set\n",
        "          shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                      my_data_dir + '/train/' + label + '/' + file_name)\n",
        "          \n",
        "\n",
        "        elif count <= (train_set_files_qty + validation_set_files_qty ):\n",
        "          # move given file to validation set\n",
        "          shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                      my_data_dir + '/validation/' + label + '/' + file_name)\n",
        "\n",
        "        else:\n",
        "          # move given file to test set\n",
        "          shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                  my_data_dir + '/test/' +label + '/'+ file_name)\n",
        "          \n",
        "        count += 1\n",
        "\n",
        "      os.rmdir(my_data_dir + '/' + label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conventionally, the dataset is divided such that:\n",
        "\n",
        "* The training set is 70% of the data.\n",
        "* The validation set is 10% of the data.\n",
        "* The test set is 20% of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_train_validation_test_images(my_data_dir = f\"inputs/cherry_leaves_dataset/cherry-leaves\",\n",
        "                        train_set_ratio = 0.7,\n",
        "                        validation_set_ratio=0.1,\n",
        "                        test_set_ratio=0.2\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check the number of image files in each folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1472 images in train/healthy\n",
            "There are 1472 images in train/powdery_mildew\n",
            "There are 422 images in test/healthy\n",
            "There are 422 images in test/powdery_mildew\n",
            "There are 210 images in validation/healthy\n",
            "There are 210 images in validation/powdery_mildew\n"
          ]
        }
      ],
      "source": [
        "sets = ['train', 'test', 'validation']\n",
        "labels = ['healthy', 'powdery_mildew']\n",
        "for set in sets:\n",
        "    for label in labels:\n",
        "        number_of_files = len(os.listdir(f'inputs/cherry_leaves_dataset/cherry-leaves/{set}/{label}'))\n",
        "        print(f'There are {number_of_files} images in {set}/{label}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that each set has an even distribution of images across both labels, healthy and powdery_mildew. Additionally, we see that the images are split in the correct ratio between train, test and validation sets: the train set has by far the highest number of images, and the test set has approximately twice as many images as the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusions and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The dataset has no non-image files, and the files are now split in the desired ratio between test, train and validation sets.\n",
        "* Next, we will proceed to data visualisation."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
